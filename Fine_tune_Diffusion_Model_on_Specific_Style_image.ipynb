{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine-tuning Stable Diffusion XL with Dreambooth and LoRA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/17LHoxqYGjwX-K0LgJkhbGeZ4tHqJJ3Gr?usp=sharing)\n",
    "[![Open in SageMaker Studio](https://studiolab.sagemaker.aws/studiolab.svg)](https://studiolab.sagemaker.aws/import/github/adhiiisetiawan/SYN_DAM-TUTORIAL-PRICAI-2024/blob/main/Diffusion_Generate_Data.ipynb)\n",
    "\n",
    "This notebook demonstrates how to fine-tune Stable Diffusion models using the Dreambooth technique. It covers two specific models:\n",
    "\n",
    "1. **Stable Diffusion XL (SDXL)**: This section shows the process of fine-tuning SDXL using a LoRA (Low-Rank Adaptation) approach. It utilizes a custom dataset and focuses on training with a specific instance prompt.\n",
    "\n",
    "2. **Stable Diffusion 3 (SD3)**: This section guides through fine-tuning SD3 using LoRA as well.  It leverages a pre-existing dog image dataset and demonstrates training with a personalized prompt.\n",
    "\n",
    "The notebook uses the `diffusers` library from Hugging Face, along with the `accelerate` library for efficient training.  It also integrates with `wandb` for experiment tracking.\n",
    "\n",
    "**Key goals of this notebook:**\n",
    "\n",
    "* Understand the steps involved in fine-tuning Stable Diffusion models for image generation.\n",
    "* Learn how to apply Dreambooth LoRA training for both SDXL and SD3.\n",
    "* Leverage existing datasets and customize training parameters.\n",
    "* Track training progress using `wandb`.\n",
    "\n",
    "Let's explore the code and learn how to personalize these powerful image generation models!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LH7gfQW95TWh",
    "outputId": "68353379-b888-409f-a591-7c787cfb5da6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sat Oct 12 09:04:55 2024       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 550.90.07              Driver Version: 550.90.07      CUDA Version: 12.4     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA GeForce RTX 4090        On  |   00000000:02:00.0 Off |                  Off |\n",
      "|  0%   27C    P8             14W /  450W |       2MiB /  24564MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|  No running processes found                                                             |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GtbeZdqj5TWi",
    "outputId": "a12ece72-7526-45a0-cacf-1e46140b7933"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting huggingface_hub\n",
      "  Downloading huggingface_hub-0.25.2-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (3.9.0)\n",
      "Collecting fsspec>=2023.5.0 (from huggingface_hub)\n",
      "  Downloading fsspec-2024.9.0-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (6.0.1)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (2.31.0)\n",
      "Collecting tqdm>=4.42.1 (from huggingface_hub)\n",
      "  Downloading tqdm-4.66.5-py3-none-any.whl.metadata (57 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.6/57.6 kB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (4.4.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (1.26.13)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (2022.12.7)\n",
      "Downloading huggingface_hub-0.25.2-py3-none-any.whl (436 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m436.6/436.6 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading fsspec-2024.9.0-py3-none-any.whl (179 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m179.3/179.3 kB\u001b[0m \u001b[31m32.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tqdm-4.66.5-py3-none-any.whl (78 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.4/78.4 kB\u001b[0m \u001b[31m30.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: tqdm, fsspec, huggingface_hub\n",
      "  Attempting uninstall: fsspec\n",
      "    Found existing installation: fsspec 2023.4.0\n",
      "    Uninstalling fsspec-2023.4.0:\n",
      "      Successfully uninstalled fsspec-2023.4.0\n",
      "Successfully installed fsspec-2024.9.0 huggingface_hub-0.25.2 tqdm-4.66.5\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install huggingface_hub wandb datasets bitsandbytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gZoujcB55TWl",
    "outputId": "c917c4ca-dc37-4dd0-b642-da645d5860fa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (9.3.0)\n",
      "Collecting Pillow\n",
      "  Downloading pillow-10.4.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (9.2 kB)\n",
      "Downloading pillow-10.4.0-cp310-cp310-manylinux_2_28_x86_64.whl (4.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m19.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: Pillow\n",
      "  Attempting uninstall: Pillow\n",
      "    Found existing installation: Pillow 9.3.0\n",
      "    Uninstalling Pillow-9.3.0:\n",
      "      Successfully uninstalled Pillow-9.3.0\n",
      "Successfully installed Pillow-10.4.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade Pillow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "J_g2hmFfrFO8"
   },
   "outputs": [],
   "source": [
    "from huggingface_hub import notebook_login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "referenced_widgets": [
      "0e3b800eeef7445a8a548b0cd10b7567"
     ]
    },
    "id": "GPOVLAss5TWj",
    "outputId": "8df244d8-f829-489c-c8b5-190d5f08d318"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e3b800eeef7445a8a548b0cd10b7567",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mcpR46VCrM9p",
    "outputId": "aee48243-75f6-439e-c82e-d014c9c88617"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'diffusers'...\n",
      "remote: Enumerating objects: 71873, done.\u001b[K\n",
      "remote: Counting objects: 100% (10654/10654), done.\u001b[K\n",
      "remote: Compressing objects: 100% (985/985), done.\u001b[K\n",
      "remote: Total 71873 (delta 10210), reused 9776 (delta 9603), pack-reused 61219 (from 1)\u001b[K\n",
      "Receiving objects: 100% (71873/71873), 49.99 MiB | 21.34 MiB/s, done.\n",
      "Resolving deltas: 100% (53306/53306), done.\n",
      "Updating files: 100% (1584/1584), done.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/huggingface/diffusers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PTvPtDRGrnSV",
    "outputId": "b4578be6-00fb-4417-f800-7b728f23528c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/workspace/diffusers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/IPython/core/magics/osm.py:417: UserWarning: using dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    }
   ],
   "source": [
    "%cd diffusers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "E-dhxNRNrb0i",
    "outputId": "b00acc49-a24d-4938-9972-4501a62ffaff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CITATION.cff\t    MANIFEST.in    _typos.toml\texamples\tsrc\n",
      "CODE_OF_CONDUCT.md  Makefile\t   benchmarks\tpyproject.toml\ttests\n",
      "CONTRIBUTING.md     PHILOSOPHY.md  docker\tscripts\t\tutils\n",
      "LICENSE\t\t    README.md\t   docs\t\tsetup.py\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OKGclcCsrkH6",
    "outputId": "175f45ba-a534-43d9-8ef4-0b5789946151"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obtaining file:///workspace/diffusers\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Checking if build backend supports build_editable ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build editable ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing editable metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/lib/python3/dist-packages (from diffusers==0.31.0.dev0) (4.6.4)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from diffusers==0.31.0.dev0) (3.9.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from diffusers==0.31.0.dev0) (0.25.2)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from diffusers==0.31.0.dev0) (1.24.1)\n",
      "Collecting regex!=2019.12.17 (from diffusers==0.31.0.dev0)\n",
      "  Downloading regex-2024.9.11-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.5/40.5 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from diffusers==0.31.0.dev0) (2.32.3)\n",
      "Collecting safetensors>=0.3.1 (from diffusers==0.31.0.dev0)\n",
      "  Downloading safetensors-0.4.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from diffusers==0.31.0.dev0) (9.3.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.23.2->diffusers==0.31.0.dev0) (2024.6.1)\n",
      "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.23.2->diffusers==0.31.0.dev0) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.23.2->diffusers==0.31.0.dev0) (6.0.1)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.23.2->diffusers==0.31.0.dev0) (4.66.5)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.23.2->diffusers==0.31.0.dev0) (4.4.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->diffusers==0.31.0.dev0) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->diffusers==0.31.0.dev0) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->diffusers==0.31.0.dev0) (1.26.13)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->diffusers==0.31.0.dev0) (2022.12.7)\n",
      "Downloading regex-2024.9.11-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (782 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m782.7/782.7 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading safetensors-0.4.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (435 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m435.0/435.0 kB\u001b[0m \u001b[31m55.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hBuilding wheels for collected packages: diffusers\n",
      "  Building editable for diffusers (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for diffusers: filename=diffusers-0.31.0.dev0-0.editable-py3-none-any.whl size=11102 sha256=8b586ba1d320161fadf6da1cdc8ef0fa9eb4b376762d6e18d14d1859e947e4a2\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-19u57b4e/wheels/86/d0/a3/783dfd30a3a65321046424bb8e359b826b7cf724c77d331554\n",
      "Successfully built diffusers\n",
      "Installing collected packages: safetensors, regex, diffusers\n",
      "Successfully installed diffusers-0.31.0.dev0 regex-2024.9.11 safetensors-0.4.5\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install -e ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MHly-1IZr1lV",
    "outputId": "c015476b-d82c-4aa8-d822-72671282e940"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/workspace/diffusers/examples/dreambooth\n"
     ]
    }
   ],
   "source": [
    "%cd examples/dreambooth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SKFX1Vgwro_R",
    "outputId": "487d4042-3591-40a8-db08-81a12a2a554a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting accelerate>=0.31.0 (from -r requirements_sd3.txt (line 1))\n",
      "  Downloading accelerate-1.0.1-py3-none-any.whl.metadata (19 kB)\n",
      "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from -r requirements_sd3.txt (line 2)) (0.16.0+cu118)\n",
      "Collecting transformers>=4.41.2 (from -r requirements_sd3.txt (line 3))\n",
      "  Downloading transformers-4.45.2-py3-none-any.whl.metadata (44 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.4/44.4 kB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting ftfy (from -r requirements_sd3.txt (line 4))\n",
      "  Downloading ftfy-6.3.0-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting tensorboard (from -r requirements_sd3.txt (line 5))\n",
      "  Downloading tensorboard-2.18.0-py3-none-any.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: Jinja2 in /usr/local/lib/python3.10/dist-packages (from -r requirements_sd3.txt (line 6)) (3.1.2)\n",
      "Collecting peft==0.11.1 (from -r requirements_sd3.txt (line 7))\n",
      "  Downloading peft-0.11.1-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting sentencepiece (from -r requirements_sd3.txt (line 8))\n",
      "  Downloading sentencepiece-0.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.7 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from peft==0.11.1->-r requirements_sd3.txt (line 7)) (1.24.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from peft==0.11.1->-r requirements_sd3.txt (line 7)) (23.2)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from peft==0.11.1->-r requirements_sd3.txt (line 7)) (5.9.6)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from peft==0.11.1->-r requirements_sd3.txt (line 7)) (6.0.1)\n",
      "Requirement already satisfied: torch>=1.13.0 in /usr/local/lib/python3.10/dist-packages (from peft==0.11.1->-r requirements_sd3.txt (line 7)) (2.1.0+cu118)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from peft==0.11.1->-r requirements_sd3.txt (line 7)) (4.66.5)\n",
      "Requirement already satisfied: safetensors in /usr/local/lib/python3.10/dist-packages (from peft==0.11.1->-r requirements_sd3.txt (line 7)) (0.4.5)\n",
      "Requirement already satisfied: huggingface-hub>=0.17.0 in /usr/local/lib/python3.10/dist-packages (from peft==0.11.1->-r requirements_sd3.txt (line 7)) (0.25.2)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision->-r requirements_sd3.txt (line 2)) (2.32.3)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision->-r requirements_sd3.txt (line 2)) (9.3.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft==0.11.1->-r requirements_sd3.txt (line 7)) (3.9.0)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft==0.11.1->-r requirements_sd3.txt (line 7)) (4.4.0)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft==0.11.1->-r requirements_sd3.txt (line 7)) (1.12)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft==0.11.1->-r requirements_sd3.txt (line 7)) (3.0)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft==0.11.1->-r requirements_sd3.txt (line 7)) (2024.6.1)\n",
      "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft==0.11.1->-r requirements_sd3.txt (line 7)) (2.1.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.41.2->-r requirements_sd3.txt (line 3)) (2024.9.11)\n",
      "Collecting tokenizers<0.21,>=0.20 (from transformers>=4.41.2->-r requirements_sd3.txt (line 3))\n",
      "  Downloading tokenizers-0.20.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
      "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from ftfy->-r requirements_sd3.txt (line 4)) (0.2.9)\n",
      "Collecting absl-py>=0.4 (from tensorboard->-r requirements_sd3.txt (line 5))\n",
      "  Downloading absl_py-2.1.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting grpcio>=1.48.2 (from tensorboard->-r requirements_sd3.txt (line 5))\n",
      "  Downloading grpcio-1.66.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.9 kB)\n",
      "Collecting markdown>=2.6.8 (from tensorboard->-r requirements_sd3.txt (line 5))\n",
      "  Downloading Markdown-3.7-py3-none-any.whl.metadata (7.0 kB)\n",
      "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements_sd3.txt (line 5)) (5.28.2)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements_sd3.txt (line 5)) (68.2.2)\n",
      "Requirement already satisfied: six>1.9 in /usr/lib/python3/dist-packages (from tensorboard->-r requirements_sd3.txt (line 5)) (1.16.0)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard->-r requirements_sd3.txt (line 5))\n",
      "  Downloading tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl.metadata (1.1 kB)\n",
      "Collecting werkzeug>=1.0.1 (from tensorboard->-r requirements_sd3.txt (line 5))\n",
      "  Downloading werkzeug-3.0.4-py3-none-any.whl.metadata (3.7 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from Jinja2->-r requirements_sd3.txt (line 6)) (2.1.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision->-r requirements_sd3.txt (line 2)) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision->-r requirements_sd3.txt (line 2)) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision->-r requirements_sd3.txt (line 2)) (1.26.13)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision->-r requirements_sd3.txt (line 2)) (2022.12.7)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.13.0->peft==0.11.1->-r requirements_sd3.txt (line 7)) (1.3.0)\n",
      "Downloading peft-0.11.1-py3-none-any.whl (251 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m251.6/251.6 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading accelerate-1.0.1-py3-none-any.whl (330 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m330.9/330.9 kB\u001b[0m \u001b[31m19.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading transformers-4.45.2-py3-none-any.whl (9.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.9/9.9 MB\u001b[0m \u001b[31m61.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading ftfy-6.3.0-py3-none-any.whl (44 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.8/44.8 kB\u001b[0m \u001b[31m16.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tensorboard-2.18.0-py3-none-any.whl (5.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m128.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading sentencepiece-0.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m260.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading absl_py-2.1.0-py3-none-any.whl (133 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.7/133.7 kB\u001b[0m \u001b[31m67.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading grpcio-1.66.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.8/5.8 MB\u001b[0m \u001b[31m136.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading Markdown-3.7-py3-none-any.whl (106 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.3/106.3 kB\u001b[0m \u001b[31m29.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl (6.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m27.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading tokenizers-0.20.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m332.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading werkzeug-3.0.4-py3-none-any.whl (227 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m227.6/227.6 kB\u001b[0m \u001b[31m95.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: sentencepiece, werkzeug, tensorboard-data-server, markdown, grpcio, ftfy, absl-py, tensorboard, tokenizers, accelerate, transformers, peft\n",
      "Successfully installed absl-py-2.1.0 accelerate-1.0.1 ftfy-6.3.0 grpcio-1.66.2 markdown-3.7 peft-0.11.1 sentencepiece-0.2.0 tensorboard-2.18.0 tensorboard-data-server-0.7.2 tokenizers-0.20.1 transformers-4.45.2 werkzeug-3.0.4\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install -r requirements_sd3.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Tg2y0rVerzjC",
    "outputId": "f6153b02-4d1d-49e3-f456-d09d84de720e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/root/.cache/huggingface/accelerate/default_config.yaml')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from accelerate.utils import write_basic_config\n",
    "write_basic_config()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iMpKej0r1V4r"
   },
   "source": [
    "# SDXL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8tWtoLYO1Xoz",
    "outputId": "c2808524-d25c-46c5-849a-911d8b1e83a5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "README.md\t\t test_dreambooth_lora_edm.py\n",
      "README_flux.md\t\t test_dreambooth_lora_flux.py\n",
      "README_sd3.md\t\t test_dreambooth_lora_sd3.py\n",
      "README_sdxl.md\t\t test_dreambooth_sd3.py\n",
      "requirements.txt\t train_dreambooth.py\n",
      "requirements_flax.txt\t train_dreambooth_flax.py\n",
      "requirements_flux.txt\t train_dreambooth_flux.py\n",
      "requirements_sd3.txt\t train_dreambooth_lora.py\n",
      "requirements_sdxl.txt\t train_dreambooth_lora_flux.py\n",
      "test_dreambooth.py\t train_dreambooth_lora_sd3.py\n",
      "test_dreambooth_flux.py  train_dreambooth_lora_sdxl.py\n",
      "test_dreambooth_lora.py  train_dreambooth_sd3.py\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Z8WtvaZe1fCC",
    "outputId": "2d22be17-11a3-4527-e2c7-e6336ea41c4b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: accelerate>=0.16.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements_sdxl.txt (line 1)) (1.0.1)\n",
      "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from -r requirements_sdxl.txt (line 2)) (0.16.0+cu118)\n",
      "Requirement already satisfied: transformers>=4.25.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements_sdxl.txt (line 3)) (4.45.2)\n",
      "Requirement already satisfied: ftfy in /usr/local/lib/python3.10/dist-packages (from -r requirements_sdxl.txt (line 4)) (6.3.0)\n",
      "Requirement already satisfied: tensorboard in /usr/local/lib/python3.10/dist-packages (from -r requirements_sdxl.txt (line 5)) (2.18.0)\n",
      "Requirement already satisfied: Jinja2 in /usr/local/lib/python3.10/dist-packages (from -r requirements_sdxl.txt (line 6)) (3.1.2)\n",
      "Collecting peft==0.7.0 (from -r requirements_sdxl.txt (line 7))\n",
      "  Downloading peft-0.7.0-py3-none-any.whl.metadata (25 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from peft==0.7.0->-r requirements_sdxl.txt (line 7)) (1.24.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from peft==0.7.0->-r requirements_sdxl.txt (line 7)) (23.2)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from peft==0.7.0->-r requirements_sdxl.txt (line 7)) (5.9.6)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from peft==0.7.0->-r requirements_sdxl.txt (line 7)) (6.0.1)\n",
      "Requirement already satisfied: torch>=1.13.0 in /usr/local/lib/python3.10/dist-packages (from peft==0.7.0->-r requirements_sdxl.txt (line 7)) (2.1.0+cu118)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from peft==0.7.0->-r requirements_sdxl.txt (line 7)) (4.66.5)\n",
      "Requirement already satisfied: safetensors in /usr/local/lib/python3.10/dist-packages (from peft==0.7.0->-r requirements_sdxl.txt (line 7)) (0.4.5)\n",
      "Requirement already satisfied: huggingface-hub>=0.17.0 in /usr/local/lib/python3.10/dist-packages (from peft==0.7.0->-r requirements_sdxl.txt (line 7)) (0.25.2)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision->-r requirements_sdxl.txt (line 2)) (2.32.3)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision->-r requirements_sdxl.txt (line 2)) (9.3.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft==0.7.0->-r requirements_sdxl.txt (line 7)) (3.9.0)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft==0.7.0->-r requirements_sdxl.txt (line 7)) (4.4.0)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft==0.7.0->-r requirements_sdxl.txt (line 7)) (1.12)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft==0.7.0->-r requirements_sdxl.txt (line 7)) (3.0)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft==0.7.0->-r requirements_sdxl.txt (line 7)) (2024.6.1)\n",
      "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft==0.7.0->-r requirements_sdxl.txt (line 7)) (2.1.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.25.1->-r requirements_sdxl.txt (line 3)) (2024.9.11)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.25.1->-r requirements_sdxl.txt (line 3)) (0.20.1)\n",
      "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from ftfy->-r requirements_sdxl.txt (line 4)) (0.2.9)\n",
      "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements_sdxl.txt (line 5)) (2.1.0)\n",
      "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements_sdxl.txt (line 5)) (1.66.2)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements_sdxl.txt (line 5)) (3.7)\n",
      "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements_sdxl.txt (line 5)) (5.28.2)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements_sdxl.txt (line 5)) (68.2.2)\n",
      "Requirement already satisfied: six>1.9 in /usr/lib/python3/dist-packages (from tensorboard->-r requirements_sdxl.txt (line 5)) (1.16.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements_sdxl.txt (line 5)) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements_sdxl.txt (line 5)) (3.0.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from Jinja2->-r requirements_sdxl.txt (line 6)) (2.1.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision->-r requirements_sdxl.txt (line 2)) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision->-r requirements_sdxl.txt (line 2)) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision->-r requirements_sdxl.txt (line 2)) (1.26.13)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision->-r requirements_sdxl.txt (line 2)) (2022.12.7)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.13.0->peft==0.7.0->-r requirements_sdxl.txt (line 7)) (1.3.0)\n",
      "Downloading peft-0.7.0-py3-none-any.whl (168 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.3/168.3 kB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: peft\n",
      "  Attempting uninstall: peft\n",
      "    Found existing installation: peft 0.11.1\n",
      "    Uninstalling peft-0.11.1:\n",
      "      Successfully uninstalled peft-0.11.1\n",
      "Successfully installed peft-0.7.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip3 install -r requirements_sdxl.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oRyPwzutbtvo"
   },
   "source": [
    "Here's a table with all the arguments for the `train_dreambooth_lora_sdxl.py` script:\n",
    "\n",
    "| Argument                             | Description                                     | Example Value                                    |\n",
    "|--------------------------------------|-------------------------------------------------|--------------------------------------------------|\n",
    "| `--pretrained_model_name_or_path`    | Path or identifier for the pretrained model     | `\"stabilityai/stable-diffusion-xl-base-1.0\"`     |\n",
    "| `--dataset_name`                     | Name of the dataset to use                      | `\"adhisetiawan/food-bakso-img\"`                  |\n",
    "| `--pretrained_vae_model_name_or_path`| Path or identifier for the pretrained VAE model | `\"madebyollin/sdxl-vae-fp16-fix\"`                |\n",
    "| `--output_dir`                       | Directory to save the trained model             | `\"lora-trained-xl\"`                              |\n",
    "| `--use_8bit_adam`                    | Use 8-bit Adam optimizer                        | Flag only (no value)                             |\n",
    "| `--mixed_precision`                  | Type of mixed precision                         | `\"bf16\"`                                         |\n",
    "| `--train_text_encoder`               | Train the text encoder                          | Flag only (no value)                             |\n",
    "| `--instance_prompt`                  | Instance prompt for training                    | `\"a photo of bakso\"`                             |\n",
    "| `--resolution`                       | Resolution for training images                  | `1024`                                           |\n",
    "| `--train_batch_size`                 | Batch size for training                         | `1`                                              |\n",
    "| `--gradient_accumulation_steps`      | Steps for gradient accumulation                 | `4`                                              |\n",
    "| `--learning_rate`                    | Learning rate for training                      | `1e-4`                                           |\n",
    "| `--lr_scheduler`                     | Learning rate scheduler                         | `\"constant\"`                                     |\n",
    "| `--lr_warmup_steps`                  | Warmup steps for learning rate                  | `0`                                              |\n",
    "| `--max_train_steps`                  | Maximum number of training steps                | `500`                                            |\n",
    "| `--validation_prompt`                | Prompt used for validation                      | `\"A photo of bakso in a bowl\"`                   |\n",
    "| `--validation_epochs`                | Epoch interval for validation                   | `5`                                              |\n",
    "| `--report_to`                        | Reporting platform (e.g., `wandb`)              | `\"wandb\"`                                        |\n",
    "| `--seed`                             | Random seed for reproducibility                 | `\"0\"`                                            |\n",
    "| `--hub_model_id`                     | Model identifier for pushing to the hub         | `\"sdxl-base-test\"`                               |\n",
    "| `--push_to_hub`                      | Push the model to the hub                       | Flag only (no value)                             |\n",
    "\n",
    "This table summarizes each argument, its description, and example values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QVsRHaZzsVCb"
   },
   "outputs": [],
   "source": [
    "!accelerate launch train_dreambooth_lora_sdxl.py \\\n",
    "  --pretrained_model_name_or_path=\"stabilityai/stable-diffusion-xl-base-1.0\"  \\\n",
    "  --dataset_name=\"adhisetiawan/food-bakso-img\" \\\n",
    "  --pretrained_vae_model_name_or_path=\"madebyollin/sdxl-vae-fp16-fix\" \\\n",
    "  --output_dir=\"lora-trained-xl\" \\\n",
    "  --use_8bit_adam \\\n",
    "  --mixed_precision=\"bf16\" \\\n",
    "  --train_text_encoder \\\n",
    "  --instance_prompt=\"a photo of bakso\" \\\n",
    "  --resolution=1024 \\\n",
    "  --train_batch_size=1 \\\n",
    "  --gradient_accumulation_steps=4 \\\n",
    "  --learning_rate=1e-4 \\\n",
    "  --lr_scheduler=\"constant\" \\\n",
    "  --lr_warmup_steps=0 \\\n",
    "  --max_train_steps=500 \\\n",
    "  --validation_prompt=\"A photo of bakso in a bowl\" \\\n",
    "  --validation_epochs=5 \\\n",
    "  --report_to=\"wandb\" \\\n",
    "  --seed=\"0\" \\\n",
    "  --hub_model_id=\"sdxl-base-test\" \\\n",
    "  --push_to_hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7XkeoTX_1MQq"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J7JOJgRs2GSB",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Stable Diffusion 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8oLLJkhwsMCt"
   },
   "outputs": [],
   "source": [
    "!export MODEL_NAME=\"stabilityai/stable-diffusion-3-medium-diffusers\"\n",
    "!export INSTANCE_DIR=\"dog/\"\n",
    "!export OUTPUT_DIR=\"trained-sd3-lora\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NHpMFGCmsTiD",
    "outputId": "fc1aa19c-0461-4862-e27f-8e8bf89435f3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "README_flux.md\t       requirements.txt\t\t     train_dreambooth_flax.py\n",
      "README.md\t       test_dreambooth_flux.py\t     train_dreambooth_flux.py\n",
      "README_sd3.md\t       test_dreambooth_lora_edm.py   train_dreambooth_lora_flux.py\n",
      "README_sdxl.md\t       test_dreambooth_lora_flux.py  train_dreambooth_lora.py\n",
      "requirements_flax.txt  test_dreambooth_lora.py\t     train_dreambooth_lora_sd3.py\n",
      "requirements_flux.txt  test_dreambooth_lora_sd3.py   train_dreambooth_lora_sdxl.py\n",
      "requirements_sd3.txt   test_dreambooth.py\t     train_dreambooth.py\n",
      "requirements_sdxl.txt  test_dreambooth_sd3.py\t     train_dreambooth_sd3.py\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "q1z1JKtTxU68"
   },
   "outputs": [],
   "source": [
    "import wandb\n",
    "wandb.require(\"core\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yxPpLLFusRla",
    "outputId": "1db9a726-ed7f-41cf-f6eb-172bfd83dc6e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-08-15 11:33:11.715459: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-08-15 11:33:11.732157: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-08-15 11:33:11.753417: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-08-15 11:33:11.759931: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-08-15 11:33:11.775496: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-08-15 11:33:12.853786: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "08/15/2024 11:33:14 - INFO - __main__ - Distributed environment: NO\n",
      "Num processes: 1\n",
      "Process index: 0\n",
      "Local process index: 0\n",
      "Device: cuda\n",
      "\n",
      "Mixed precision type: fp16\n",
      "\n",
      "tokenizer/tokenizer_config.json: 100% 705/705 [00:00<00:00, 4.49MB/s]\n",
      "tokenizer/vocab.json: 100% 1.06M/1.06M [00:00<00:00, 7.38MB/s]\n",
      "tokenizer/merges.txt: 100% 525k/525k [00:00<00:00, 3.96MB/s]\n",
      "tokenizer/special_tokens_map.json: 100% 588/588 [00:00<00:00, 4.46MB/s]\n",
      "tokenizer_2/tokenizer_config.json: 100% 856/856 [00:00<00:00, 6.46MB/s]\n",
      "tokenizer_2/special_tokens_map.json: 100% 576/576 [00:00<00:00, 4.66MB/s]\n",
      "tokenizer_3/tokenizer_config.json: 100% 20.6k/20.6k [00:00<00:00, 80.7MB/s]\n",
      "spiece.model: 100% 792k/792k [00:00<00:00, 6.11MB/s]\n",
      "tokenizer_3/tokenizer.json: 100% 2.42M/2.42M [00:00<00:00, 28.7MB/s]\n",
      "tokenizer_3/special_tokens_map.json: 100% 2.54k/2.54k [00:00<00:00, 19.6MB/s]\n",
      "You set `add_prefix_space`. The tokenizer needs to be converted from the slow tokenizers\n",
      "text_encoder/config.json: 100% 574/574 [00:00<00:00, 4.83MB/s]\n",
      "You are using a model of type clip_text_model to instantiate a model of type . This is not supported for all configurations of models and can yield errors.\n",
      "text_encoder_2/config.json: 100% 570/570 [00:00<00:00, 4.36MB/s]\n",
      "You are using a model of type clip_text_model to instantiate a model of type . This is not supported for all configurations of models and can yield errors.\n",
      "text_encoder_3/config.json: 100% 740/740 [00:00<00:00, 5.65MB/s]\n",
      "You are using a model of type t5 to instantiate a model of type . This is not supported for all configurations of models and can yield errors.\n",
      "scheduler/scheduler_config.json: 100% 141/141 [00:00<00:00, 1.05MB/s]\n",
      "{'base_image_seq_len', 'use_dynamic_shifting', 'max_shift', 'max_image_seq_len', 'base_shift'} was not found in config. Values will be initialized to default values.\n",
      "model.safetensors: 100% 247M/247M [00:01<00:00, 155MB/s]\n",
      "model.safetensors: 100% 1.39G/1.39G [00:08<00:00, 159MB/s]\n",
      "(…)t_encoder_3/model.safetensors.index.json: 100% 19.9k/19.9k [00:00<00:00, 103MB/s]\n",
      "Downloading shards:   0% 0/2 [00:00<?, ?it/s]\n",
      "model-00001-of-00002.safetensors:   0% 0.00/4.99G [00:00<?, ?B/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:   0% 21.0M/4.99G [00:00<00:32, 155MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:   1% 41.9M/4.99G [00:00<00:31, 159MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:   1% 62.9M/4.99G [00:00<00:30, 160MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:   2% 83.9M/4.99G [00:00<00:30, 160MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:   2% 105M/4.99G [00:00<00:30, 160MB/s] \u001b[A\n",
      "model-00001-of-00002.safetensors:   3% 126M/4.99G [00:00<00:30, 160MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:   3% 147M/4.99G [00:00<00:30, 161MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:   3% 168M/4.99G [00:01<00:30, 160MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:   4% 189M/4.99G [00:01<00:29, 160MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:   4% 210M/4.99G [00:01<00:29, 160MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:   5% 231M/4.99G [00:01<00:29, 160MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:   5% 252M/4.99G [00:01<00:29, 160MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:   5% 273M/4.99G [00:01<00:29, 160MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:   6% 294M/4.99G [00:01<00:29, 160MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:   6% 315M/4.99G [00:01<00:29, 160MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:   7% 336M/4.99G [00:02<00:45, 102MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:   7% 357M/4.99G [00:02<00:40, 114MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:   8% 377M/4.99G [00:02<00:36, 125MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:   8% 398M/4.99G [00:02<00:34, 134MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:   8% 419M/4.99G [00:02<00:32, 141MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:   9% 440M/4.99G [00:02<00:31, 146MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:   9% 461M/4.99G [00:03<00:30, 150MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  10% 482M/4.99G [00:03<00:29, 153MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  10% 503M/4.99G [00:03<00:28, 155MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  10% 524M/4.99G [00:03<00:28, 157MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  11% 545M/4.99G [00:03<00:28, 158MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  11% 566M/4.99G [00:03<00:27, 158MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  12% 587M/4.99G [00:03<00:27, 159MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  12% 608M/4.99G [00:04<00:27, 159MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  13% 629M/4.99G [00:04<00:27, 160MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  13% 650M/4.99G [00:04<00:27, 160MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  13% 671M/4.99G [00:04<00:26, 160MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  14% 692M/4.99G [00:04<00:26, 160MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  14% 713M/4.99G [00:04<00:26, 161MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  15% 734M/4.99G [00:04<00:26, 161MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  15% 755M/4.99G [00:04<00:26, 161MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  16% 776M/4.99G [00:05<00:26, 160MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  16% 797M/4.99G [00:05<00:26, 160MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  16% 818M/4.99G [00:05<00:26, 159MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  17% 839M/4.99G [00:05<00:26, 159MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  17% 860M/4.99G [00:05<00:25, 160MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  18% 881M/4.99G [00:05<00:25, 160MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  18% 902M/4.99G [00:05<00:25, 158MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  18% 923M/4.99G [00:06<00:26, 156MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  19% 944M/4.99G [00:06<00:26, 155MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  19% 965M/4.99G [00:06<00:26, 155MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  20% 986M/4.99G [00:06<00:26, 154MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  20% 1.01G/4.99G [00:06<00:25, 154MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  21% 1.03G/4.99G [00:06<00:25, 156MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  21% 1.05G/4.99G [00:06<00:25, 158MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  21% 1.07G/4.99G [00:06<00:24, 159MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  22% 1.09G/4.99G [00:07<00:24, 160MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  22% 1.11G/4.99G [00:07<00:24, 160MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  23% 1.13G/4.99G [00:07<00:24, 159MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  23% 1.15G/4.99G [00:07<00:24, 160MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  24% 1.17G/4.99G [00:07<00:23, 160MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  24% 1.20G/4.99G [00:07<00:23, 160MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  24% 1.22G/4.99G [00:07<00:23, 160MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  25% 1.24G/4.99G [00:08<00:23, 160MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  25% 1.26G/4.99G [00:08<00:23, 161MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  26% 1.28G/4.99G [00:08<00:23, 160MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  26% 1.30G/4.99G [00:08<00:23, 160MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  26% 1.32G/4.99G [00:08<00:22, 160MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  27% 1.34G/4.99G [00:08<00:22, 161MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  27% 1.36G/4.99G [00:08<00:22, 161MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  28% 1.38G/4.99G [00:08<00:22, 160MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  28% 1.41G/4.99G [00:09<00:22, 161MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  29% 1.43G/4.99G [00:09<00:22, 161MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  29% 1.45G/4.99G [00:09<00:22, 161MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  29% 1.47G/4.99G [00:09<00:21, 161MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  30% 1.49G/4.99G [00:09<00:21, 161MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  30% 1.51G/4.99G [00:09<00:21, 161MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  31% 1.53G/4.99G [00:09<00:21, 161MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  31% 1.55G/4.99G [00:09<00:21, 161MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  31% 1.57G/4.99G [00:10<00:21, 161MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  32% 1.59G/4.99G [00:10<00:21, 161MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  32% 1.61G/4.99G [00:10<00:21, 161MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  33% 1.64G/4.99G [00:10<00:20, 161MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  33% 1.66G/4.99G [00:10<00:20, 161MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  34% 1.68G/4.99G [00:10<00:20, 160MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  34% 1.70G/4.99G [00:10<00:20, 160MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  34% 1.72G/4.99G [00:11<00:20, 161MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  35% 1.74G/4.99G [00:11<00:20, 161MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  35% 1.76G/4.99G [00:11<00:20, 161MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  36% 1.78G/4.99G [00:11<00:19, 161MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  36% 1.80G/4.99G [00:11<00:19, 161MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  37% 1.82G/4.99G [00:11<00:19, 161MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  37% 1.85G/4.99G [00:11<00:19, 160MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  37% 1.87G/4.99G [00:11<00:19, 159MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  38% 1.89G/4.99G [00:12<00:19, 159MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  38% 1.91G/4.99G [00:12<00:19, 159MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  39% 1.93G/4.99G [00:12<00:19, 158MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  39% 1.95G/4.99G [00:12<00:19, 157MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  39% 1.97G/4.99G [00:12<00:19, 157MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  40% 1.99G/4.99G [00:12<00:19, 156MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  40% 2.01G/4.99G [00:12<00:19, 156MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  41% 2.03G/4.99G [00:12<00:18, 156MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  41% 2.06G/4.99G [00:13<00:18, 156MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  42% 2.08G/4.99G [00:13<00:18, 156MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  42% 2.10G/4.99G [00:13<00:18, 156MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  42% 2.12G/4.99G [00:13<00:18, 156MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  43% 2.14G/4.99G [00:13<00:23, 119MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  43% 2.16G/4.99G [00:13<00:22, 128MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  44% 2.18G/4.99G [00:14<00:20, 136MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  44% 2.20G/4.99G [00:14<00:19, 141MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  45% 2.22G/4.99G [00:14<00:19, 146MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  45% 2.24G/4.99G [00:14<00:18, 149MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  45% 2.26G/4.99G [00:14<00:18, 152MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  46% 2.29G/4.99G [00:14<00:17, 154MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  46% 2.31G/4.99G [00:14<00:17, 155MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  47% 2.33G/4.99G [00:15<00:17, 155MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  47% 2.35G/4.99G [00:15<00:17, 155MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  47% 2.37G/4.99G [00:15<00:16, 156MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  48% 2.39G/4.99G [00:15<00:16, 156MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  48% 2.41G/4.99G [00:15<00:16, 154MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  49% 2.43G/4.99G [00:15<00:16, 155MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  49% 2.45G/4.99G [00:15<00:16, 155MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  50% 2.47G/4.99G [00:15<00:16, 156MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  50% 2.50G/4.99G [00:16<00:16, 156MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  50% 2.52G/4.99G [00:16<00:16, 155MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  51% 2.54G/4.99G [00:16<00:15, 156MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  51% 2.56G/4.99G [00:16<00:15, 157MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  52% 2.58G/4.99G [00:16<00:15, 157MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  52% 2.60G/4.99G [00:16<00:15, 158MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  52% 2.62G/4.99G [00:16<00:14, 159MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  53% 2.64G/4.99G [00:17<00:14, 159MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  53% 2.66G/4.99G [00:17<00:14, 160MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  54% 2.68G/4.99G [00:17<00:14, 160MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  54% 2.71G/4.99G [00:17<00:14, 160MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  55% 2.73G/4.99G [00:17<00:14, 159MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  55% 2.75G/4.99G [00:17<00:14, 160MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  55% 2.77G/4.99G [00:17<00:13, 160MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  56% 2.79G/4.99G [00:17<00:13, 160MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  56% 2.81G/4.99G [00:18<00:13, 160MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  57% 2.83G/4.99G [00:18<00:13, 160MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  57% 2.85G/4.99G [00:18<00:13, 160MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  58% 2.87G/4.99G [00:18<00:13, 161MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  58% 2.89G/4.99G [00:18<00:13, 161MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  58% 2.92G/4.99G [00:18<00:12, 161MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  59% 2.94G/4.99G [00:18<00:12, 161MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  59% 2.96G/4.99G [00:18<00:12, 161MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  60% 2.98G/4.99G [00:19<00:12, 159MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  60% 3.00G/4.99G [00:19<00:12, 159MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  60% 3.02G/4.99G [00:19<00:12, 159MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  61% 3.04G/4.99G [00:19<00:12, 160MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  61% 3.06G/4.99G [00:19<00:12, 160MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  62% 3.08G/4.99G [00:19<00:11, 160MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  62% 3.10G/4.99G [00:19<00:11, 160MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  63% 3.12G/4.99G [00:20<00:11, 160MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  63% 3.15G/4.99G [00:20<00:11, 161MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  63% 3.17G/4.99G [00:20<00:11, 161MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  64% 3.19G/4.99G [00:20<00:11, 161MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  64% 3.21G/4.99G [00:20<00:11, 160MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  65% 3.23G/4.99G [00:20<00:10, 161MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  65% 3.25G/4.99G [00:20<00:10, 161MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  66% 3.27G/4.99G [00:20<00:10, 161MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  66% 3.29G/4.99G [00:21<00:10, 161MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  66% 3.31G/4.99G [00:21<00:10, 160MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  67% 3.33G/4.99G [00:21<00:10, 160MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  67% 3.36G/4.99G [00:21<00:10, 160MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  68% 3.38G/4.99G [00:21<00:10, 159MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  68% 3.40G/4.99G [00:21<00:10, 159MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  68% 3.42G/4.99G [00:21<00:09, 159MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  69% 3.44G/4.99G [00:21<00:09, 159MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  69% 3.46G/4.99G [00:22<00:09, 159MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  70% 3.48G/4.99G [00:22<00:14, 103MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  70% 3.50G/4.99G [00:22<00:12, 115MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  71% 3.52G/4.99G [00:22<00:11, 125MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  71% 3.54G/4.99G [00:22<00:10, 133MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  71% 3.57G/4.99G [00:23<00:10, 138MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  72% 3.59G/4.99G [00:23<00:09, 143MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  72% 3.61G/4.99G [00:23<00:09, 147MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  73% 3.63G/4.99G [00:23<00:09, 150MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  73% 3.65G/4.99G [00:23<00:08, 152MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  73% 3.67G/4.99G [00:23<00:08, 153MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  74% 3.69G/4.99G [00:23<00:08, 154MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  74% 3.71G/4.99G [00:23<00:08, 155MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  75% 3.73G/4.99G [00:24<00:08, 155MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  75% 3.75G/4.99G [00:24<00:08, 155MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  76% 3.77G/4.99G [00:24<00:07, 155MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  76% 3.80G/4.99G [00:24<00:07, 156MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  76% 3.82G/4.99G [00:24<00:07, 156MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  77% 3.84G/4.99G [00:24<00:07, 156MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  77% 3.86G/4.99G [00:24<00:07, 157MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  78% 3.88G/4.99G [00:25<00:07, 143MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  78% 3.90G/4.99G [00:25<00:07, 147MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  79% 3.92G/4.99G [00:25<00:07, 150MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  79% 3.94G/4.99G [00:25<00:06, 153MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  79% 3.96G/4.99G [00:25<00:06, 154MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  80% 3.98G/4.99G [00:25<00:06, 156MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  80% 4.01G/4.99G [00:25<00:06, 156MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  81% 4.03G/4.99G [00:26<00:06, 157MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  81% 4.05G/4.99G [00:26<00:05, 158MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  81% 4.07G/4.99G [00:29<00:44, 20.6MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  82% 4.09G/4.99G [00:29<00:32, 27.7MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  82% 4.11G/4.99G [00:29<00:24, 36.6MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  83% 4.13G/4.99G [00:29<00:18, 47.6MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  83% 4.15G/4.99G [00:29<00:13, 60.4MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  84% 4.17G/4.99G [00:29<00:11, 74.0MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  84% 4.19G/4.99G [00:30<00:09, 87.5MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  84% 4.22G/4.99G [00:30<00:07, 101MB/s] \u001b[A\n",
      "model-00001-of-00002.safetensors:  85% 4.24G/4.99G [00:30<00:06, 114MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  85% 4.26G/4.99G [00:30<00:05, 124MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  86% 4.28G/4.99G [00:30<00:05, 133MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  86% 4.30G/4.99G [00:30<00:04, 140MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  86% 4.32G/4.99G [00:30<00:04, 146MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  87% 4.34G/4.99G [00:30<00:04, 150MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  87% 4.36G/4.99G [00:31<00:04, 153MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  88% 4.38G/4.99G [00:31<00:04, 144MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  88% 4.40G/4.99G [00:31<00:04, 143MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  89% 4.42G/4.99G [00:31<00:03, 148MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  89% 4.45G/4.99G [00:31<00:03, 152MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  89% 4.47G/4.99G [00:31<00:03, 154MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  90% 4.49G/4.99G [00:31<00:03, 156MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  90% 4.51G/4.99G [00:32<00:03, 158MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  91% 4.53G/4.99G [00:32<00:02, 159MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  91% 4.55G/4.99G [00:32<00:02, 159MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  92% 4.57G/4.99G [00:32<00:02, 160MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  92% 4.59G/4.99G [00:32<00:02, 160MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  92% 4.61G/4.99G [00:32<00:02, 148MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  93% 4.63G/4.99G [00:32<00:02, 152MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  93% 4.66G/4.99G [00:33<00:02, 154MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  94% 4.68G/4.99G [00:33<00:02, 156MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  94% 4.70G/4.99G [00:33<00:01, 157MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  94% 4.72G/4.99G [00:33<00:01, 159MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  95% 4.74G/4.99G [00:33<00:01, 159MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  95% 4.76G/4.99G [00:33<00:01, 160MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  96% 4.78G/4.99G [00:33<00:01, 160MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  96% 4.80G/4.99G [00:33<00:01, 161MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  97% 4.82G/4.99G [00:34<00:01, 161MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  97% 4.84G/4.99G [00:34<00:00, 161MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  97% 4.87G/4.99G [00:34<00:00, 161MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  98% 4.89G/4.99G [00:34<00:00, 161MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  98% 4.91G/4.99G [00:34<00:00, 161MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  99% 4.93G/4.99G [00:34<00:00, 161MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  99% 4.95G/4.99G [00:34<00:00, 161MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors: 100% 4.97G/4.99G [00:34<00:00, 161MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors: 100% 4.99G/4.99G [00:35<00:00, 141MB/s]\n",
      "Downloading shards:  50% 1/2 [00:35<00:35, 35.49s/it]\n",
      "model-00002-of-00002.safetensors:   0% 0.00/4.53G [00:00<?, ?B/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:   0% 21.0M/4.53G [00:00<00:32, 140MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:   1% 41.9M/4.53G [00:00<00:30, 148MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:   1% 62.9M/4.53G [00:00<00:29, 152MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:   2% 83.9M/4.53G [00:00<00:28, 154MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:   2% 105M/4.53G [00:00<00:28, 155MB/s] \u001b[A\n",
      "model-00002-of-00002.safetensors:   3% 126M/4.53G [00:00<00:28, 155MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:   3% 147M/4.53G [00:00<00:28, 152MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:   4% 168M/4.53G [00:01<00:28, 152MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:   4% 189M/4.53G [00:01<00:28, 154MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:   5% 210M/4.53G [00:01<00:27, 156MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:   5% 231M/4.53G [00:01<00:27, 157MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:   6% 252M/4.53G [00:01<00:27, 158MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:   6% 273M/4.53G [00:01<00:26, 158MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:   6% 294M/4.53G [00:01<00:26, 158MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:   7% 315M/4.53G [00:02<00:27, 155MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:   7% 336M/4.53G [00:02<00:26, 156MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:   8% 357M/4.53G [00:02<00:26, 157MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:   8% 377M/4.53G [00:02<00:26, 158MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:   9% 398M/4.53G [00:02<00:25, 159MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:   9% 419M/4.53G [00:02<00:25, 159MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  10% 440M/4.53G [00:02<00:25, 159MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  10% 461M/4.53G [00:02<00:25, 160MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  11% 482M/4.53G [00:03<00:25, 160MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  11% 503M/4.53G [00:03<00:25, 160MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  12% 524M/4.53G [00:03<00:24, 160MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  12% 545M/4.53G [00:03<00:24, 161MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  12% 566M/4.53G [00:03<00:24, 161MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  13% 587M/4.53G [00:03<00:24, 161MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  13% 608M/4.53G [00:03<00:24, 160MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  14% 629M/4.53G [00:03<00:24, 161MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  14% 650M/4.53G [00:04<00:24, 161MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  15% 671M/4.53G [00:04<00:24, 161MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  15% 692M/4.53G [00:04<00:23, 160MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  16% 713M/4.53G [00:04<00:23, 160MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  16% 734M/4.53G [00:04<00:23, 161MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  17% 755M/4.53G [00:04<00:23, 160MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  17% 776M/4.53G [00:04<00:23, 161MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  18% 797M/4.53G [00:05<00:25, 147MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  18% 818M/4.53G [00:05<00:24, 151MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  19% 839M/4.53G [00:05<00:24, 153MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  19% 860M/4.53G [00:05<00:23, 155MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  19% 881M/4.53G [00:05<00:23, 157MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  20% 902M/4.53G [00:05<00:23, 156MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  20% 923M/4.53G [00:05<00:22, 157MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  21% 944M/4.53G [00:06<00:22, 158MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  21% 965M/4.53G [00:06<00:22, 158MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  22% 986M/4.53G [00:06<00:22, 159MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  22% 1.01G/4.53G [00:06<00:22, 160MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  23% 1.03G/4.53G [00:06<00:21, 160MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  23% 1.05G/4.53G [00:06<00:21, 159MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  24% 1.07G/4.53G [00:06<00:21, 159MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  24% 1.09G/4.53G [00:06<00:21, 159MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  25% 1.11G/4.53G [00:07<00:21, 159MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  25% 1.13G/4.53G [00:07<00:21, 159MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  25% 1.15G/4.53G [00:07<00:21, 158MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  26% 1.17G/4.53G [00:07<00:21, 158MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  26% 1.20G/4.53G [00:07<00:21, 158MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  27% 1.22G/4.53G [00:07<00:21, 158MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  27% 1.24G/4.53G [00:07<00:20, 157MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  28% 1.26G/4.53G [00:07<00:20, 157MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  28% 1.28G/4.53G [00:08<00:20, 157MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  29% 1.30G/4.53G [00:08<00:20, 157MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  29% 1.32G/4.53G [00:08<00:20, 157MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  30% 1.34G/4.53G [00:08<00:20, 157MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  30% 1.36G/4.53G [00:08<00:20, 156MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  31% 1.38G/4.53G [00:08<00:20, 155MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  31% 1.41G/4.53G [00:08<00:20, 155MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  31% 1.43G/4.53G [00:09<00:20, 154MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  32% 1.45G/4.53G [00:09<00:19, 156MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  32% 1.47G/4.53G [00:09<00:19, 157MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  33% 1.49G/4.53G [00:09<00:20, 149MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  33% 1.51G/4.53G [00:09<00:20, 148MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  34% 1.53G/4.53G [00:09<00:19, 150MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  34% 1.55G/4.53G [00:09<00:19, 152MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  35% 1.57G/4.53G [00:10<00:19, 154MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  35% 1.59G/4.53G [00:10<00:18, 155MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  36% 1.61G/4.53G [00:10<00:18, 155MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  36% 1.64G/4.53G [00:10<00:18, 156MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  37% 1.66G/4.53G [00:10<00:18, 156MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  37% 1.68G/4.53G [00:10<00:18, 156MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  37% 1.70G/4.53G [00:10<00:18, 155MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  38% 1.72G/4.53G [00:10<00:18, 155MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  38% 1.74G/4.53G [00:11<00:17, 156MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  39% 1.76G/4.53G [00:11<00:17, 156MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  39% 1.78G/4.53G [00:11<00:17, 157MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  40% 1.80G/4.53G [00:11<00:17, 159MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  40% 1.82G/4.53G [00:11<00:16, 159MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  41% 1.85G/4.53G [00:11<00:16, 160MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  41% 1.87G/4.53G [00:11<00:16, 160MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  42% 1.89G/4.53G [00:12<00:16, 161MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  42% 1.91G/4.53G [00:12<00:16, 161MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  43% 1.93G/4.53G [00:12<00:16, 160MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  43% 1.95G/4.53G [00:12<00:16, 161MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  44% 1.97G/4.53G [00:12<00:16, 153MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  44% 1.99G/4.53G [00:12<00:16, 156MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  44% 2.01G/4.53G [00:12<00:16, 157MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  45% 2.03G/4.53G [00:12<00:15, 158MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  45% 2.06G/4.53G [00:13<00:15, 159MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  46% 2.08G/4.53G [00:13<00:15, 159MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  46% 2.10G/4.53G [00:13<00:16, 148MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  47% 2.12G/4.53G [00:13<00:16, 151MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  47% 2.14G/4.53G [00:13<00:15, 153MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  48% 2.16G/4.53G [00:13<00:15, 154MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  48% 2.18G/4.53G [00:13<00:15, 156MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  49% 2.20G/4.53G [00:14<00:14, 157MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  49% 2.22G/4.53G [00:14<00:14, 158MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  50% 2.24G/4.53G [00:14<00:14, 159MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  50% 2.26G/4.53G [00:14<00:14, 160MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  50% 2.29G/4.53G [00:14<00:14, 160MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  51% 2.31G/4.53G [00:14<00:13, 160MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  51% 2.33G/4.53G [00:14<00:13, 161MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  52% 2.35G/4.53G [00:14<00:13, 161MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  52% 2.37G/4.53G [00:15<00:20, 103MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  53% 2.39G/4.53G [00:15<00:18, 116MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  53% 2.41G/4.53G [00:15<00:16, 126MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  54% 2.43G/4.53G [00:15<00:16, 127MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  54% 2.45G/4.53G [00:15<00:15, 135MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  55% 2.47G/4.53G [00:16<00:14, 141MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  55% 2.50G/4.53G [00:16<00:13, 146MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  56% 2.52G/4.53G [00:16<00:13, 150MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  56% 2.54G/4.53G [00:16<00:14, 141MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  56% 2.56G/4.53G [00:16<00:14, 138MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  57% 2.58G/4.53G [00:16<00:13, 143MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  57% 2.60G/4.53G [00:16<00:13, 148MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  58% 2.62G/4.53G [00:17<00:12, 151MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  58% 2.64G/4.53G [00:17<00:12, 153MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  59% 2.66G/4.53G [00:17<00:12, 155MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  59% 2.68G/4.53G [00:17<00:11, 156MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  60% 2.71G/4.53G [00:17<00:11, 155MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  60% 2.73G/4.53G [00:17<00:11, 154MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  61% 2.75G/4.53G [00:17<00:11, 153MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  61% 2.77G/4.53G [00:17<00:11, 153MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  62% 2.79G/4.53G [00:18<00:11, 152MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  62% 2.81G/4.53G [00:18<00:11, 153MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  62% 2.83G/4.53G [00:18<00:11, 154MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  63% 2.85G/4.53G [00:18<00:10, 155MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  63% 2.87G/4.53G [00:18<00:10, 155MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  64% 2.89G/4.53G [00:18<00:11, 138MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  64% 2.92G/4.53G [00:18<00:11, 143MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  65% 2.94G/4.53G [00:19<00:10, 147MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  65% 2.96G/4.53G [00:19<00:10, 150MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  66% 2.98G/4.53G [00:19<00:10, 152MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  66% 3.00G/4.53G [00:19<00:10, 153MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  67% 3.02G/4.53G [00:19<00:09, 154MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  67% 3.04G/4.53G [00:19<00:09, 154MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  68% 3.06G/4.53G [00:19<00:09, 155MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  68% 3.08G/4.53G [00:20<00:09, 155MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  69% 3.10G/4.53G [00:20<00:09, 156MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  69% 3.12G/4.53G [00:20<00:08, 157MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  69% 3.15G/4.53G [00:20<00:08, 158MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  70% 3.17G/4.53G [00:20<00:08, 159MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  70% 3.19G/4.53G [00:20<00:08, 159MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  71% 3.21G/4.53G [00:20<00:08, 160MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  71% 3.23G/4.53G [00:23<01:02, 20.7MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  72% 3.25G/4.53G [00:24<00:45, 28.0MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  72% 3.27G/4.53G [00:24<00:33, 37.3MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  73% 3.29G/4.53G [00:24<00:25, 48.4MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  73% 3.31G/4.53G [00:24<00:19, 61.2MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  74% 3.33G/4.53G [00:24<00:15, 75.2MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  74% 3.36G/4.53G [00:24<00:13, 89.5MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  75% 3.38G/4.53G [00:24<00:11, 103MB/s] \u001b[A\n",
      "model-00002-of-00002.safetensors:  75% 3.40G/4.53G [00:24<00:09, 116MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  75% 3.42G/4.53G [00:25<00:08, 126MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  76% 3.44G/4.53G [00:25<00:08, 135MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  76% 3.46G/4.53G [00:25<00:07, 142MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  77% 3.48G/4.53G [00:25<00:07, 147MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  77% 3.50G/4.53G [00:25<00:06, 151MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  78% 3.52G/4.53G [00:25<00:10, 99.8MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  78% 3.54G/4.53G [00:26<00:08, 113MB/s] \u001b[A\n",
      "model-00002-of-00002.safetensors:  79% 3.57G/4.53G [00:26<00:07, 124MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  79% 3.59G/4.53G [00:26<00:07, 133MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  80% 3.61G/4.53G [00:26<00:06, 140MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  80% 3.63G/4.53G [00:26<00:06, 146MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  81% 3.65G/4.53G [00:26<00:05, 150MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  81% 3.67G/4.53G [00:26<00:05, 153MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  81% 3.69G/4.53G [00:27<00:05, 155MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  82% 3.71G/4.53G [00:27<00:05, 157MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  82% 3.73G/4.53G [00:27<00:05, 158MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  83% 3.75G/4.53G [00:27<00:04, 159MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  83% 3.77G/4.53G [00:27<00:04, 160MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  84% 3.80G/4.53G [00:27<00:04, 160MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  84% 3.82G/4.53G [00:27<00:04, 161MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  85% 3.84G/4.53G [00:27<00:04, 161MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  85% 3.86G/4.53G [00:28<00:04, 161MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  86% 3.88G/4.53G [00:28<00:04, 160MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  86% 3.90G/4.53G [00:28<00:03, 160MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  87% 3.92G/4.53G [00:28<00:03, 160MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  87% 3.94G/4.53G [00:28<00:03, 160MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  87% 3.96G/4.53G [00:28<00:03, 160MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  88% 3.98G/4.53G [00:28<00:03, 160MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  88% 4.01G/4.53G [00:28<00:03, 160MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  89% 4.03G/4.53G [00:29<00:03, 160MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  89% 4.05G/4.53G [00:29<00:03, 159MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  90% 4.07G/4.53G [00:29<00:02, 159MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  90% 4.09G/4.53G [00:29<00:02, 159MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  91% 4.11G/4.53G [00:29<00:02, 159MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  91% 4.13G/4.53G [00:29<00:02, 160MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  92% 4.15G/4.53G [00:29<00:02, 160MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  92% 4.17G/4.53G [00:30<00:02, 159MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  93% 4.19G/4.53G [00:30<00:02, 159MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  93% 4.22G/4.53G [00:30<00:01, 158MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  94% 4.24G/4.53G [00:30<00:01, 157MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  94% 4.26G/4.53G [00:30<00:01, 157MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  94% 4.28G/4.53G [00:30<00:01, 156MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  95% 4.30G/4.53G [00:30<00:01, 156MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  95% 4.32G/4.53G [00:30<00:01, 156MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  96% 4.34G/4.53G [00:31<00:01, 156MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  96% 4.36G/4.53G [00:31<00:01, 155MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  97% 4.38G/4.53G [00:31<00:01, 147MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  97% 4.40G/4.53G [00:31<00:00, 150MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  98% 4.42G/4.53G [00:31<00:00, 145MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  98% 4.45G/4.53G [00:31<00:00, 147MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  99% 4.47G/4.53G [00:31<00:00, 151MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  99% 4.49G/4.53G [00:32<00:00, 148MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors: 100% 4.51G/4.53G [00:32<00:00, 151MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors: 100% 4.53G/4.53G [00:32<00:00, 140MB/s]\n",
      "Downloading shards: 100% 2/2 [01:08<00:00, 34.02s/it]\n",
      "Loading checkpoint shards: 100% 2/2 [00:12<00:00,  6.06s/it]\n",
      "vae/config.json: 100% 739/739 [00:00<00:00, 6.22MB/s]\n",
      "diffusion_pytorch_model.safetensors: 100% 168M/168M [00:01<00:00, 131MB/s]\n",
      "{'mid_block_add_attention'} was not found in config. Values will be initialized to default values.\n",
      "transformer/config.json: 100% 372/372 [00:00<00:00, 3.38MB/s]\n",
      "diffusion_pytorch_model.safetensors: 100% 4.17G/4.17G [00:27<00:00, 153MB/s]\n",
      "08/15/2024 11:35:45 - INFO - datasets - PyTorch version 2.3.1+cu121 available.\n",
      "08/15/2024 11:35:45 - INFO - datasets - Polars version 0.20.2 available.\n",
      "08/15/2024 11:35:45 - INFO - datasets - TensorFlow version 2.17.0 available.\n",
      "08/15/2024 11:35:45 - INFO - datasets - JAX version 0.4.26 available.\n",
      "Downloading data: 100% 677k/677k [00:00<00:00, 2.70MB/s]\n",
      "Downloading data: 100% 1.16M/1.16M [00:00<00:00, 5.85MB/s]\n",
      "Downloading data: 100% 1.40M/1.40M [00:00<00:00, 12.7MB/s]\n",
      "Downloading data: 100% 1.19M/1.19M [00:00<00:00, 4.30MB/s]\n",
      "Downloading data: 100% 1.17M/1.17M [00:00<00:00, 6.63MB/s]\n",
      "Generating train split: 100% 5/5 [00:00<00:00, 981.95 examples/s]\n",
      "08/15/2024 11:35:49 - INFO - __main__ - No caption column provided, defaulting to instance_prompt for all images. If your dataset contains captions/prompts for the images, make sure to specify the column as --caption_column\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend. Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: (1) Create a W&B account\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: (2) Use an existing W&B account\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: (3) Don't visualize my results\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Enter your choice: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You chose 'Use an existing W&B account'\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.17.6\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/diffusers/examples/dreambooth/wandb/run-20240815_113605-bwn70ab8\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mlyric-surf-4\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/adhiisetiawan/dreambooth-sd3-lora\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/adhiisetiawan/dreambooth-sd3-lora/runs/bwn70ab8\u001b[0m\n",
      "08/15/2024 11:36:05 - INFO - __main__ - ***** Running training *****\n",
      "08/15/2024 11:36:05 - INFO - __main__ -   Num examples = 5\n",
      "08/15/2024 11:36:05 - INFO - __main__ -   Num batches each epoch = 5\n",
      "08/15/2024 11:36:05 - INFO - __main__ -   Num Epochs = 250\n",
      "08/15/2024 11:36:05 - INFO - __main__ -   Instantaneous batch size per device = 1\n",
      "08/15/2024 11:36:05 - INFO - __main__ -   Total train batch size (w. parallel, distributed & accumulation) = 4\n",
      "08/15/2024 11:36:05 - INFO - __main__ -   Gradient Accumulation steps = 4\n",
      "08/15/2024 11:36:05 - INFO - __main__ -   Total optimization steps = 500\n",
      "Steps:   0% 2/500 [00:01<05:31,  1.50it/s, loss=0.029, lr=1e-5]\n",
      "Downloading shards: 100% 2/2 [00:00<00:00, 6168.09it/s]\n",
      "\n",
      "Loading checkpoint shards:   0% 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "Loading checkpoint shards:  50% 1/2 [00:06<00:06,  6.50s/it]\u001b[A\n",
      "Loading checkpoint shards: 100% 2/2 [00:12<00:00,  6.33s/it]\n",
      "\n",
      "model_index.json: 100% 706/706 [00:00<00:00, 3.39MB/s]\n",
      "\n",
      "Loading pipeline components...:   0% 0/9 [00:00<?, ?it/s]\u001b[ALoaded tokenizer as CLIPTokenizer from `tokenizer` subfolder of stabilityai/stable-diffusion-3-medium-diffusers.\n",
      "Loaded tokenizer_2 as CLIPTokenizer from `tokenizer_2` subfolder of stabilityai/stable-diffusion-3-medium-diffusers.\n",
      "\n",
      "Loading pipeline components...:  22% 2/9 [00:00<00:00, 15.44it/s]\u001b[ALoaded tokenizer_3 as T5TokenizerFast from `tokenizer_3` subfolder of stabilityai/stable-diffusion-3-medium-diffusers.\n",
      "\n",
      "Loading pipeline components...:  89% 8/9 [00:00<00:00, 21.72it/s]\u001b[A{'base_image_seq_len', 'use_dynamic_shifting', 'max_shift', 'max_image_seq_len', 'base_shift'} was not found in config. Values will be initialized to default values.\n",
      "Loaded scheduler as FlowMatchEulerDiscreteScheduler from `scheduler` subfolder of stabilityai/stable-diffusion-3-medium-diffusers.\n",
      "Loading pipeline components...: 100% 9/9 [00:00<00:00, 23.57it/s]\n",
      "08/15/2024 11:36:24 - INFO - __main__ - Running validation... \n",
      " Generating 4 images with prompt: A photo of sks dog in a bucket.\n",
      "Traceback (most recent call last):\n",
      "  File \"/content/diffusers/examples/dreambooth/train_dreambooth_lora_sd3.py\", line 1873, in <module>\n",
      "    main(args)\n",
      "  File \"/content/diffusers/examples/dreambooth/train_dreambooth_lora_sd3.py\", line 1791, in main\n",
      "    images = log_validation(\n",
      "  File \"/content/diffusers/examples/dreambooth/train_dreambooth_lora_sd3.py\", line 197, in log_validation\n",
      "    images = [pipeline(**pipeline_args, generator=generator).images[0] for _ in range(args.num_validation_images)]\n",
      "  File \"/content/diffusers/examples/dreambooth/train_dreambooth_lora_sd3.py\", line 197, in <listcomp>\n",
      "    images = [pipeline(**pipeline_args, generator=generator).images[0] for _ in range(args.num_validation_images)]\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/content/diffusers/src/diffusers/pipelines/stable_diffusion_3/pipeline_stable_diffusion_3.py\", line 926, in __call__\n",
      "    image = self.vae.decode(latents, return_dict=False)[0]\n",
      "  File \"/content/diffusers/src/diffusers/utils/accelerate_utils.py\", line 46, in wrapper\n",
      "    return method(self, *args, **kwargs)\n",
      "  File \"/content/diffusers/src/diffusers/models/autoencoders/autoencoder_kl.py\", line 321, in decode\n",
      "    decoded = self._decode(z).sample\n",
      "  File \"/content/diffusers/src/diffusers/models/autoencoders/autoencoder_kl.py\", line 292, in _decode\n",
      "    dec = self.decoder(z)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/content/diffusers/src/diffusers/models/autoencoders/vae.py\", line 337, in forward\n",
      "    sample = up_block(sample, latent_embeds)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/content/diffusers/src/diffusers/models/unets/unet_2d_blocks.py\", line 2750, in forward\n",
      "    hidden_states = upsampler(hidden_states)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/content/diffusers/src/diffusers/models/upsampling.py\", line 180, in forward\n",
      "    hidden_states = self.conv(hidden_states)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py\", line 460, in forward\n",
      "    return self._conv_forward(input, self.weight, self.bias)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py\", line 456, in _conv_forward\n",
      "    return F.conv2d(input, weight, bias, self.stride,\n",
      "torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 1024.00 MiB. GPU \n",
      "\u001b[1;34mwandb\u001b[0m: 🚀 View run \u001b[33mlyric-surf-4\u001b[0m at: \u001b[34mhttps://wandb.ai/adhiisetiawan/dreambooth-sd3-lora/runs/bwn70ab8\u001b[0m\n",
      "\u001b[1;34mwandb\u001b[0m: Find logs at: \u001b[1;35mwandb/run-20240815_113605-bwn70ab8/logs\u001b[0m\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/bin/accelerate\", line 8, in <module>\n",
      "    sys.exit(main())\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/accelerate/commands/accelerate_cli.py\", line 48, in main\n",
      "    args.func(args)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/accelerate/commands/launch.py\", line 1097, in launch_command\n",
      "    simple_launcher(args)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/accelerate/commands/launch.py\", line 703, in simple_launcher\n",
      "    raise subprocess.CalledProcessError(returncode=process.returncode, cmd=cmd)\n",
      "subprocess.CalledProcessError: Command '['/usr/bin/python3', 'train_dreambooth_lora_sd3.py', '--pretrained_model_name_or_path=stabilityai/stable-diffusion-3-medium-diffusers', '--dataset_name=diffusers/dog-example', '--output_dir=trained-sd3-lora', '--mixed_precision=fp16', '--instance_prompt=a photo of sks dog', '--resolution=512', '--train_batch_size=1', '--gradient_accumulation_steps=4', '--learning_rate=1e-5', '--report_to=wandb', '--lr_scheduler=constant', '--lr_warmup_steps=0', '--max_train_steps=500', '--validation_prompt=A photo of sks dog in a bucket', '--validation_epochs=25', '--seed=0', '--push_to_hub']' returned non-zero exit status 1.\n"
     ]
    }
   ],
   "source": [
    "!accelerate launch train_dreambooth_lora_sd3.py \\\n",
    "  --pretrained_model_name_or_path=\"stabilityai/stable-diffusion-3-medium-diffusers\"  \\\n",
    "  --dataset_name=\"diffusers/dog-example\" \\\n",
    "  --output_dir=\"trained-sd3-lora\" \\\n",
    "  --mixed_precision=\"fp16\" \\\n",
    "  --instance_prompt=\"a photo of sks dog\" \\\n",
    "  --resolution=512 \\\n",
    "  --train_batch_size=1 \\\n",
    "  --gradient_accumulation_steps=4 \\\n",
    "  --learning_rate=1e-5 \\\n",
    "  --report_to=\"wandb\" \\\n",
    "  --lr_scheduler=\"constant\" \\\n",
    "  --lr_warmup_steps=0 \\\n",
    "  --max_train_steps=500 \\\n",
    "  --validation_prompt=\"A photo of sks dog in a bucket\" \\\n",
    "  --validation_epochs=25 \\\n",
    "  --seed=\"0\" \\\n",
    "  --push_to_hub"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "J7JOJgRs2GSB"
   ],
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
